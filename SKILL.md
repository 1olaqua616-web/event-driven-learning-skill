---
name: event-driven-learning
description: 事件驱动深度学习回路。当用户遇到真实问题/现象想深入理解时触发。五阶段闭合回路：事件驱动 → 概念扫盲 → 网状发散 → 深度分析 → Review回路。所有交付物存入本地文件夹。当用户说 /edl 或描述"遇到一个现象想搞懂"时触发。
---

# event-driven-learning — 事件驱动深度学习回路

## 设计哲学

从真实事件/问题出发，以核心概念为锚点向外网状发散，通过结构化辩证分析深化理解，最终通过 Review 闭合回路。

**理论基础**：融合 Kolb 经验学习循环、PBL 问题驱动学习、Novak 概念图、Spiro 认知灵活性理论、Bruner 螺旋课程。

**核心约束**：人类工作记忆 ~4 chunk，长期记忆靠语义网络。有效学习 = 把新信息挂载到已有网络节点上。

**多视角约束**：
- 单会话内的"多视角推理"是自欺欺人——KV Cache 共享导致前序推理痕迹污染后续视角（隐式状态是一切污染的根源）
- 真正的多视角需要**进程级隔离**：开 subagent、多模型、多窗口
- KV Cache 不重新算，每次都是"历史 + 当前"的累积——空间复杂度暴力降低，但代价是视角不可能独立

## 触发

- 用户输入 `/edl` 或 `/event-driven-learning`
- 用户描述遇到了一个真实现象/问题，想搞懂背后原理
- 用户说"帮我概念扫盲"、"以 X 为原点发散"、"深度分析"等关键词

## 因果性过滤（贯穿全程的底层约束）

**目的**：比锚点机制更底层的过滤器。锚点定义"能做什么"，因果性过滤定义"该做什么"。

**规则**：
- 每条发散线索必须声明"它如何**因果地**推进锚点问题"
- 仅"相关"的线索：标记但不追，因果线索优先展开
- **硬约束**：发现对话滑入相关性聊天时，**立即退出/切断**——不反驳、不纠正。反驳和纠正本身就是相关性行为（你在花时间解释为什么不该聊这个，而不是真的在推进问题）

**判断标准**：
```
因果推进 = "因为搞懂了 X，所以能回答锚点问题的 Y 部分"
相关性聊天 = "X 和锚点问题有关，但搞懂 X 不直接帮助回答锚点"
```

## 前馈状态声明（每阶段开头）

**目的**：显式声明当前阶段的认知操作类型，约束合法行为。

**规则**：每个阶段开始时，声明当前处于以下三种状态之一：
- **发散**（阶段③）：允许引入新概念、新视角、新类比。不允许下结论
- **对齐**（阶段①②④）：允许深入、质疑、验证。不允许引入无关新概念
- **收敛**（阶段⑤）：允许总结、归档、串联。不允许新发散

**作用**：防止"在收敛阶段突然发散"或"在发散阶段急于下结论"的认知混乱。

## 五阶段回路

```
① 事件锚定 → ② 概念扫盲 → ③ 网状发散 → ④ 深度分析 → ⑤ Review 回路
      ↑                                                        │
      └──────────── 注释深化 / 新事件触发 ────────────────────────┘
```

### 阶段 ① 事件锚定 (Event Anchoring)

**状态声明**：对齐

**目标**：从用户遇到的真实事件中提取核心问题。

操作：
1. 让用户描述遇到的现象（鼓励提供截图、数据、对比）
2. **认知谦逊检查（先于一切分析）**：
   - 先**复述**用户的问题（用自己的话，不是照搬）
   - 暴露自己的理解边界："关于 X 我确定的是……不确定的是……"
   - 不要急于给出解法——"我懂"的预判是最隐蔽的认知污染源
3. AI 逐字逐句分析用户描述，提取：
   - 核心矛盾点（什么和预期不一致？）
   - 涉及的领域/概念（初步识别）
   - 用户当前的认知水平（已知 vs 未知）
4. 输出一句话总结：「你的核心问题是 X，因为 Y 和你的预期 Z 不一致」
5. 确认后进入下一阶段

### 阶段 ② 概念扫盲 (Concept Onboarding)

**状态声明**：对齐

**目标**：建立理解问题所需的最小知识节点集合。

操作：
1. 用 WebSearch 搜索权威来源（官方文档 > 技术博客 > 社区讨论）
2. 列出理解该问题所需的所有核心术语（术语表格式）
3. 每个术语：一句话定义 + 与核心问题的关系
4. **不要过度展开**——只扫盲，不深入，为阶段③留空间

### 阶段 ③ 网状发散 (Network Expansion)

**状态声明**：发散

**目标**：以核心概念为原点，构建概念网络图。

操作：
1. 画出以核心概念为中心的网状结构（ASCII 或 Mermaid）
2. **每个新视角/方向必须自带对齐声明**："这个视角回答锚点的哪个子方面"——没有声明的视角不允许展开
3. 每条边标注关系类型（因果、依赖、对比、层级）
4. 发散维度：
   - **向下**：底层原理（为什么是这样？）
   - **向上**：上层应用（这影响什么？）
   - **横向**：类比/对比概念（和什么类似？和什么不同？）
   - **横向·同构**：把核心矛盾抽象到足够高的层次，跨领域搜索已有解法。问：这个矛盾的结构，在其他领域是否已经被解决过？
   - **历史**：演进脉络（从哪来？往哪去？）
5. **主体性保护检查**（同构搜索后必做）：
   - 找到跨领域类比后，问："如果我从未见过这个类比，我自己会怎么想？"
   - 如果答案和类比完全一致 → 可能是真同构
   - 如果答案不同 → 差异点就是类比失效的边界
   - 如果已经想不起"没类比之前我怎么想的" → 已经被同化，需要退回
6. 标记用户可能感兴趣的深入方向，但不主动展开

### 阶段 ④ 深度分析 (Structured Deep Analysis)

**状态声明**：对齐

**目标**：用结构化辩证框架深入核心问题。

**强制输出格式**：

```
1) Conclusion (confidence: high/medium/low)
2) First principles — 不可约的核心：什么是确定的，什么约束在起作用。2-4 句。
3) Reasoning — 事实 vs 假设（每个假设：如果错了会怎样）。WHY, not WHAT。
4) Counter-argument — ≥1 个具体场景/数据/先例。各方什么时候成立；如何判断。
4.5) 职责反转检查 — 当前方案是"给 X 加 Y"的结构吗？如果是，检查：X 能不能直接变成 Y？Y 能不能吸收 X 的职责？反转后复杂度是否降低？
4.6) 交叉质询 — 如果前面产出了多个视角/解释（A、B...），用 B 的结论质疑 A 的因果链，反之亦然。目的不是"选出对的"，而是暴露每个视角的因果链在哪里断裂。
5) Uncertainties, risks, verification — 不确定性、风险、验证方法。每个不确定性点必须附带至少一种验证方式（写代码测试 / 查论文数据 / 构造反例 / 找到能推翻它的场景），不允许只标记"不确定"而不说怎么验证。
6) Next steps — 下一步行动
```

**完整性约束**：
- Never fabricate. "不确定" when unsure. Flag flawed premises.
- Primary sources preferred. When citing external facts, state source type and how retrieved.
- Current claims: verify via tools; disclose uncertainty.

### 阶段 ⑤ Review 回路 (Review Loop)

**状态声明**：收敛

**目标**：闭合回路，标注深化点，为下一轮螺旋做准备。

操作：
1. **总结套利三步**（Review 后必做，飞轮的复利引擎）：
   - **提炼**：一句话因果链（"因为 X → 所以 Y → 导致 Z"）
   - **打标签**：抽象为类别（如 #隐式状态污染 #进程隔离 #因果过滤）
   - **链接**：关联历史事件 / 已有知识节点
2. 回顾全部产出，标注：
   - ✅ 确认理解的点
   - ⚠️ 仍有不确定性的点
   - ❌ 本轮中被推翻的假设（显式保留推翻链：原假设 → 被什么证据/推理推翻 → 替代结论）
   - 🔗 可以进一步深入的方向
3. 用户可以选择：
   - 对某个 ⚠️ 点追加注释深化 → 回到阶段④
   - 对某个 🔗 方向展开 → 回到阶段③
   - 由此触发新事件 → 回到阶段①
   - 结束本轮学习

## 交付物规范

**所有交付物必须存入本地文件夹。**

文件夹路径：`{用户指定路径}` 或默认 `~/Desktop/{topic}-learning/`

标准交付物清单：
```
00-核心回答总结.md          ← 每次 chat 核心回答的本地副本（含 Sources）
01-概念知识网络图.md        ← 阶段②③产出
02-{主题}完整链路.md        ← 阶段③产出（从底层到应用的完整解析）
03-{子话题}分析.md          ← 阶段③中各发散方向的专题分析
04-深度分析与Review.md      ← 阶段④⑤产出
0N-{追加话题}-核心回答.md   ← 后续追问的核心回答
```

**每个文件必须包含 Sources 链接。**
**每次 chat 中给出的核心回答，都必须同步存入文件夹。**

## 质量约束

### 反幻觉
- 可以说不知道：没有找到信息时，说"未找到"，不编造
- 提取必须有出处：说"5个要点"就得逐条指出来源
- 越合理越要怀疑：AI 幻觉的逻辑是 pattern → 自动补全 → "听起来对" → 通过直觉检查 → 但从未存在于原文
- 发布前 spot check：引用类内容，抽查 1-2 条回原文确认

### 搜索优先级
1. 官方文档 / API docs
2. 权威技术博客（有数据支撑）
3. 社区讨论（标注"社区观点，未经官方确认"）

### Tone
- Clear, direct, no filler
- 默认中文，除非用户要求其他语言
- Be rigorous, dialectical. Priority: accuracy > usefulness > brevity.

## 与其他 Skill 的关系

| 场景 | 使用 |
|------|------|
| 遇到真实问题想搞懂原理 | → `/edl`（本 skill） |
| 系统性阅读文档/教程 | → `/study-guide` |
| 项目驱动、有可验证产出的学习 | → `/project-learning` |
| 记录学习成果到 Obsidian | → `/study-log` |

## 示例触发

用户：「我在用 amp 时发现两个几乎一样的 prompt，一个花了 $0.002，一个花了 $0.30，就差了一个空格，这是怎么回事？」

→ 阶段①：锚定"相同 prompt 微小差异导致 150 倍费用差距"
→ 阶段②：扫盲 Cache Hit/Miss、KV Cache、TTL、Tokenization
→ 阶段③：以 Cache Hit 为原点，向 Transformer 底层、API 定价、中转站生态发散
→ 阶段④：结构化分析（conclusion + first principles + reasoning + counter-argument）
→ 阶段⑤：标注验证方法，提供 next steps
