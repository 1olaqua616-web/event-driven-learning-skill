---
name: event-driven-learning
description: 事件驱动深度学习回路。当用户遇到真实问题/现象想深入理解时触发。五阶段闭合回路：事件驱动 → 概念扫盲 → 网状发散 → 深度分析 → Review回路。所有交付物存入本地文件夹。当用户说 /edl 或描述"遇到一个现象想搞懂"时触发。
---

# event-driven-learning — 事件驱动深度学习回路

## 设计哲学

从真实事件/问题出发，以核心概念为锚点向外网状发散，通过结构化辩证分析深化理解，最终通过 Review 闭合回路。

**理论基础**：融合 Kolb 经验学习循环、PBL 问题驱动学习、Novak 概念图、Spiro 认知灵活性理论、Bruner 螺旋课程。

**核心约束**：人类工作记忆 ~4 chunk，长期记忆靠语义网络。有效学习 = 把新信息挂载到已有网络节点上。

## 触发

- 用户输入 `/edl` 或 `/event-driven-learning`
- 用户描述遇到了一个真实现象/问题，想搞懂背后原理
- 用户说"帮我概念扫盲"、"以 X 为原点发散"、"深度分析"等关键词

## 五阶段回路

```
① 事件锚定 → ② 概念扫盲 → ③ 网状发散 → ④ 深度分析 → ⑤ Review 回路
      ↑                                                        │
      └──────────── 注释深化 / 新事件触发 ────────────────────────┘
```

### 阶段 ① 事件锚定 (Event Anchoring)

**目标**：从用户遇到的真实事件中提取核心问题。

操作：
1. 让用户描述遇到的现象（鼓励提供截图、数据、对比）
2. AI 逐字逐句分析用户描述，提取：
   - 核心矛盾点（什么和预期不一致？）
   - 涉及的领域/概念（初步识别）
   - 用户当前的认知水平（已知 vs 未知）
3. 输出一句话总结：「你的核心问题是 X，因为 Y 和你的预期 Z 不一致」
4. 确认后进入下一阶段

### 阶段 ② 概念扫盲 (Concept Onboarding)

**目标**：建立理解问题所需的最小知识节点集合。

操作：
1. 用 WebSearch 搜索权威来源（官方文档 > 技术博客 > 社区讨论）
2. 列出理解该问题所需的所有核心术语（术语表格式）
3. 每个术语：一句话定义 + 与核心问题的关系
4. **不要过度展开**——只扫盲，不深入，为阶段③留空间

### 阶段 ③ 网状发散 (Network Expansion)

**目标**：以核心概念为原点，构建概念网络图。

操作：
1. 画出以核心概念为中心的网状结构（ASCII 或 Mermaid）
2. 每条边标注关系类型（因果、依赖、对比、层级）
3. 发散维度：
   - **向下**：底层原理（为什么是这样？）
   - **向上**：上层应用（这影响什么？）
   - **横向**：类比/对比概念（和什么类似？和什么不同？）
   - **横向·同构**：把核心矛盾抽象到足够高的层次，跨领域搜索已有解法。问：这个矛盾的结构，在其他领域是否已经被解决过？
   - **历史**：演进脉络（从哪来？往哪去？）
4. 标记用户可能感兴趣的深入方向，但不主动展开

### 阶段 ④ 深度分析 (Structured Deep Analysis)

**目标**：用结构化辩证框架深入核心问题。

**强制输出格式**：

```
1) Conclusion (confidence: high/medium/low)
2) First principles — 不可约的核心：什么是确定的，什么约束在起作用。2-4 句。
3) Reasoning — 事实 vs 假设（每个假设：如果错了会怎样）。WHY, not WHAT。
4) Counter-argument — ≥1 个具体场景/数据/先例。各方什么时候成立；如何判断。
4.5) 职责反转检查 — 当前方案是"给 X 加 Y"的结构吗？如果是，检查：X 能不能直接变成 Y？Y 能不能吸收 X 的职责？反转后复杂度是否降低？
5) Uncertainties, risks, verification — 不确定性、风险、验证方法
6) Next steps — 下一步行动
```

**完整性约束**：
- Never fabricate. "不确定" when unsure. Flag flawed premises.
- Primary sources preferred. When citing external facts, state source type and how retrieved.
- Current claims: verify via tools; disclose uncertainty.

### 阶段 ⑤ Review 回路 (Review Loop)

**目标**：闭合回路，标注深化点，为下一轮螺旋做准备。

操作：
1. 回顾全部产出，标注：
   - ✅ 确认理解的点
   - ⚠️ 仍有不确定性的点
   - ❌ 本轮中被推翻的假设（显式保留推翻链：原假设 → 被什么证据/推理推翻 → 替代结论）
   - 🔗 可以进一步深入的方向
2. 用户可以选择：
   - 对某个 ⚠️ 点追加注释深化 → 回到阶段④
   - 对某个 🔗 方向展开 → 回到阶段③
   - 由此触发新事件 → 回到阶段①
   - 结束本轮学习

## 交付物规范

**所有交付物必须存入本地文件夹。**

文件夹路径：`{用户指定路径}` 或默认 `~/Desktop/{topic}-learning/`

标准交付物清单：
```
00-核心回答总结.md          ← 每次 chat 核心回答的本地副本（含 Sources）
01-概念知识网络图.md        ← 阶段②③产出
02-{主题}完整链路.md        ← 阶段③产出（从底层到应用的完整解析）
03-{子话题}分析.md          ← 阶段③中各发散方向的专题分析
04-深度分析与Review.md      ← 阶段④⑤产出
0N-{追加话题}-核心回答.md   ← 后续追问的核心回答
```

**每个文件必须包含 Sources 链接。**
**每次 chat 中给出的核心回答，都必须同步存入文件夹。**

## 质量约束

### 反幻觉
- 可以说不知道：没有找到信息时，说"未找到"，不编造
- 提取必须有出处：说"5个要点"就得逐条指出来源
- 越合理越要怀疑：AI 幻觉的逻辑是 pattern → 自动补全 → "听起来对" → 通过直觉检查 → 但从未存在于原文
- 发布前 spot check：引用类内容，抽查 1-2 条回原文确认

### 搜索优先级
1. 官方文档 / API docs
2. 权威技术博客（有数据支撑）
3. 社区讨论（标注"社区观点，未经官方确认"）

### Tone
- Clear, direct, no filler
- 默认中文，除非用户要求其他语言
- Be rigorous, dialectical. Priority: accuracy > usefulness > brevity.

## 与其他 Skill 的关系

| 场景 | 使用 |
|------|------|
| 遇到真实问题想搞懂原理 | → `/edl`（本 skill） |
| 系统性阅读文档/教程 | → `/study-guide` |
| 项目驱动、有可验证产出的学习 | → `/project-learning` |
| 记录学习成果到 Obsidian | → `/study-log` |

## 示例触发

用户：「我在用 amp 时发现两个几乎一样的 prompt，一个花了 $0.002，一个花了 $0.30，就差了一个空格，这是怎么回事？」

→ 阶段①：锚定"相同 prompt 微小差异导致 150 倍费用差距"
→ 阶段②：扫盲 Cache Hit/Miss、KV Cache、TTL、Tokenization
→ 阶段③：以 Cache Hit 为原点，向 Transformer 底层、API 定价、中转站生态发散
→ 阶段④：结构化分析（conclusion + first principles + reasoning + counter-argument）
→ 阶段⑤：标注验证方法，提供 next steps
